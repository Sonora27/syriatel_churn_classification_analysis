{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/joseramirez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "churn = pd.read_csv('churn.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn.drop('churn', axis = 1)\n",
    "y = churn.churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "X_trainlr, X_testlr, y_trainlr, y_testlr = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling my data for Logistic Regression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_trainlr = scaler.fit_transform(X_trainlr)\n",
    "X_testlr = scaler.transform(X_testlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(cv = 3, penalty='l2', solver = 'saga', max_iter=100000, scoring='recall', n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...convergence after 12 epochs took 0 seconds\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "convergence after 13 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "convergence after 10 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 16 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 13 epochs took 0 seconds\n",
      "rescaling...\n",
      "convergence after 11 epochs took 0 seconds\n",
      "convergence after 15 epochs took 0 seconds\n",
      "convergence after 13 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 15 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 12 epochs took 0 seconds\n",
      "convergence after 13 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 12 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 secondsconvergence after 11 epochs took 0 seconds\n",
      "\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 secondsconvergence after 4 epochs took 0 seconds\n",
      "\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_trainlr, y_trainlr)\n",
    "y_predlr = logreg.predict(X_testlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:0.1721311475409836\n"
     ]
    }
   ],
   "source": [
    "print('Recall:' + str(recall_score(y_testlr, y_predlr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('logreg', LogisticRegressionCV(cv = 3, penalty='l2', solver = 'saga', max_iter=100000, scoring='recall', n_jobs = -1, verbose = 1))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...convergence after 13 epochs took 0 seconds\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...convergence after 11 epochs took 0 seconds\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 15 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 16 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 13 epochs took 0 secondsrescaling...\n",
      "rescaling...\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...convergence after 9 epochs took 0 seconds\n",
      "\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 11 epochs took 0 seconds\n",
      "convergence after 15 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 11 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 14 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 12 epochs took 0 seconds\n",
      "convergence after 12 epochs took 0 secondsconvergence after 2 epochs took 0 seconds\n",
      "\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 10 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('logreg',\n",
       "                 LogisticRegressionCV(cv=3, max_iter=100000, n_jobs=-1,\n",
       "                                      scoring='recall', solver='saga',\n",
       "                                      verbose=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_trainlr, y_trainlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1721311475409836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_testlr, y_testlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Neighbor = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8633093525179856\n",
      "Precision: 0.7222222222222222\n",
      "Recall: 0.10655737704918032\n",
      "F-Score: 0.18571428571428572\n"
     ]
    }
   ],
   "source": [
    "## Train test split\n",
    "\n",
    "X_trainknn20, X_testknn20, y_trainknn20, y_testknn20 = train_test_split(X, y, random_state=1)\n",
    "\n",
    "## Scaling my data for KNN\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X_trainknn20 = scaler.fit_transform(X_trainknn20)  \n",
    "X_testknn20 = scaler.transform(X_testknn20)\n",
    "\n",
    "\n",
    "knn20 = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "## Fitting it to the model\n",
    "\n",
    "knn20.fit(X_trainknn20, y_trainknn20)\n",
    "\n",
    "y_pred_class20 = knn20.predict(X_testknn20)\n",
    "\n",
    "\n",
    "\n",
    "## Checking my evaluation metrics\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_testknn20, y_pred_class20)}')\n",
    "\n",
    "print(f'Precision: {precision_score(y_testknn20, y_pred_class20)}')\n",
    "\n",
    "print(f'Recall: {recall_score(y_testknn20, y_pred_class20)}')\n",
    "      \n",
    "print(f'F-Score: {f1_score(y_testknn20, y_pred_class20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Neighbor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8800959232613909\n",
      "Precision: 0.8928571428571429\n",
      "Recall: 0.20491803278688525\n",
      "F-Score: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "## Train test split\n",
    "\n",
    "X_trainknn10, X_testknn10, y_trainknn10, y_testknn10 = train_test_split(X, y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "## Scaling my data for KNN\n",
    "\n",
    "X_trainknn10 = scaler.fit_transform(X_trainknn10)  \n",
    "X_testknn10 = scaler.transform(X_testknn10)\n",
    "\n",
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "## Fitting it to the model\n",
    "\n",
    "knn10.fit(X_trainknn10, y_trainknn10)\n",
    "\n",
    "y_pred_class10 = knn10.predict(X_testknn10)\n",
    "\n",
    "\n",
    "\n",
    "## Checking my evaluation metrics\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_testknn10, y_pred_class10)}')\n",
    "\n",
    "print(f'Precision: {precision_score(y_testknn10, y_pred_class10)}')\n",
    "\n",
    "print(f'Recall: {recall_score(y_testknn10, y_pred_class10)}')\n",
    "\n",
    "print(f'F-Score: {f1_score(y_testknn10, y_pred_class10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Neighbor = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8896882494004796\n",
      "Precision:0.7777777777777778\n",
      "Recall:0.3442622950819672\n",
      "F-Score:0.4772727272727273\n"
     ]
    }
   ],
   "source": [
    "## Train test split\n",
    "\n",
    "X_trainknn5, X_testknn5, y_trainknn5, y_testknn5 = train_test_split(X, y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "\n",
    "## Scaling my data for KNN\n",
    "\n",
    "X_trainknn5 = scaler.fit_transform(X_trainknn5)  \n",
    "X_testknn5 = scaler.transform(X_testknn5)\n",
    "\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "## Fitting it to the model\n",
    "\n",
    "knn5.fit(X_trainknn5, y_trainknn5)\n",
    "\n",
    "y_pred_class5 = knn5.predict(X_testknn5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Checking my evaluation metrics\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_testknn5, y_pred_class5)}')\n",
    "\n",
    "print(f'Precision: {precision_score(y_testknn5, y_pred_class5)}')\n",
    "\n",
    "print(f'Recall: {recall_score(y_testknn5, y_pred_class5)}')\n",
    "\n",
    "print(f'F-Score: {f1_score(y_testknn5, y_pred_class5)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Neighbor = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8848920863309353\n",
      "Precision:0.703125\n",
      "Recall:0.36885245901639346\n",
      "F-Score:0.4838709677419355\n"
     ]
    }
   ],
   "source": [
    "## Train test split\n",
    "\n",
    "X_trainknn3, X_testknn3, y_trainknn3, y_testknn3 = train_test_split(X, y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X_trainknn3 = scaler.fit_transform(X_trainknn3)  \n",
    "X_testknn3 = scaler.transform(X_testknn3)\n",
    "\n",
    "## Scaling my data for KNN\n",
    "\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "## Fitting it to the model\n",
    "\n",
    "knn3.fit(X_trainknn3, y_trainknn3)\n",
    "\n",
    "y_pred_class3 = knn3.predict(X_testknn3)\n",
    "\n",
    "\n",
    "## Checking my evaluation metrics\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_testknn3, y_pred_class3)}')\n",
    "\n",
    "print(f'Precision: {precision_score(y_testknn3, y_pred_class3)}')\n",
    "\n",
    "print(f'Recall: {recall_score(y_testknn3, y_pred_class3)}')\n",
    "      \n",
    "print(f'F-Score: {f1_score(y_testknn3, y_pred_class3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This was my best performing (highest recall) KNN, so I pickled it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving my best model with pickle\n",
    "\n",
    "\n",
    "import pickle\n",
    "mod = open('knn3.pkl', 'wb')\n",
    "pickle.dump(knn3, mod)\n",
    "mod.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if Grid Search can improve my recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Train test split\n",
    "\n",
    "X_trainknngs, X_testknngs, y_trainknngs, y_testknngs = train_test_split(X, y, random_state=1)\n",
    "\n",
    "## Scaling my data\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "\n",
    "X_trainknngs = scaler.fit_transform(X_trainknngs)  \n",
    "X_testknngs = scaler.transform(X_testknngs)\n",
    "\n",
    "\n",
    "final_knn = KNeighborsClassifier()\n",
    "\n",
    "##Setting parameter dictionary\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1,50,1),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = GridSearchCV(final_knn, knn_params,scoring='recall',verbose = 1, cv = 3, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-2)]: Done 470 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-2)]: Done 861 out of 882 | elapsed:    7.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done 882 out of 882 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=-2,\n",
       "             param_grid={'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
       "                         'n_neighbors': range(1, 50),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.fit(X_trainknngs,y_trainknngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38512396694214873"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking to see best recall score from GridSearch\n",
    "\n",
    "knn_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see best estimator from GridSearch\n",
    "\n",
    "knn_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "y_predsknngs=knn_gs.best_estimator_.predict(X_testknngs)\n",
    "f1_score=f1_score(y_testknngs,y_predsknngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3710407239819004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3360655737704918\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_testknngs, y_predsknngs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch did not improve my recall, so I did not save this model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
